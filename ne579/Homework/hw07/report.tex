\documentclass{IEEEtran}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{listings}
\usepackage[citestyle=ieee,sorting=none,bibencoding=utf8,backend=biber]{biblatex}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{booktabs}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\graphicspath{{images/}}
\bibliography{bibliography}
\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\author{J.R. Powers-Luhn}
\title{Locally Weighted Regression}
\date{October 25th, 2018}

\begin{document}
\maketitle

\begin{abstract}



\end{abstract}

\section{Introduction}



\section{Methodology}

\begin{itemize}
\item Describe the locally weighted regression algorithm
\item Discuss the pros and cons of locally weighted regression over least squares regression
\item Discuss how weights are determined (Gaussian kernels)
\item Discuss how the kernel bandwidth is optimized
\item Discuss the importance of standardization for the weight calculation
\end{itemize}

\subsection{Kernel regression}



\subsection{Locally weighted regression}

\begin{equation}
\vec{b} = (\mathbf{X}^T  \mathbf{W}^T  \mathbf{W}  \mathbf{X})^{-1} \mathbf{X}^T \mathbf{W}^T \mathbf{W} \vec{y}
\label{eq:weighted regression}
\end{equation}

The $\mathbf{W}$ matrix in equation \ref{eq:weighted regression} is a diagonal matrix that has the effect of increasing the 
conditional number of the term to be inverted. This makes the equation more sensitive to small perturbations. This is counteracted 
by the fact that the data being inverted is more representative of the shape of the equation in the area around the training points. 
This trade off is balanced using cross validation to determine the generality of the models for different bandwidth parameters. 
As such, models with several different bandwidths (\numlist{0.15; 0.25; 0.50; 0.75; 1.00; 1.50; 2.00}) were trained on the training 
set and evaluated using the testing set.

\subsection{Body Composition}
A dataset of body measurements (body fat percentage, age, weight, height, adiposity index, and ten 
circumference measurements) was obtained \cite{Penrose1985}. Locally Weighted Regression was used to generate models to 
predict body fat percentage from the other predictor variables using cross validation to select 
the hyperparameter $\alpha$.

\section{Results}

\begin{table}[ht]
\caption{Lorem ipsum dolor simet}
\center
\input{table}
\end{table}

\subsection{Model Selection}
The model that was selected was that produced by the L-curve method. Its performance was not significantly 
different from the model produced using the LOO method and the larger $\alpha$ value should result in greater 
stability. Both models significantly improved on the least squares model, which had an RMSE of \num{19.35}.

The selected model was evaluated on the validation set data, producing an RMSE of \num{7.78}\% body fat.
\section{Conclusions}

A model was generated to predict body fat percentage from body composition predictors using locally weighted regression. The error of this model was \num{7.78}\% body fat. This compared unfavorably to previously generated models on these data. The error was greater than that produced by a partial least squares model (\num{4.35}\%), principal component regression (\num{4.72}\%), a best-guess linear regression (\num{4.79}\%), and a ridge regression model (\num{4.34}\%). 

\printbibliography

\onecolumn
\section{Appendix}
Python code used to perform calculations and generate graphics.
\lstset{frame=single}
\lstinputlisting[language=Python]{Homework07.py}

\end{document}